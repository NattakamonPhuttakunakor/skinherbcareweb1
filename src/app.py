from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus import thai_stopwords
import sys
import os

app = Flask(__name__)
CORS(app) 

# ========================================
# üîß ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå (Synonyms)
# ========================================
SYNONYM_MAP = {
    '‡∏õ‡∏ß‡∏î': ['‡πÄ‡∏à‡πá‡∏ö', '‡∏ó‡∏£‡∏°‡∏≤‡∏ô', '‡∏£‡∏∞‡∏ö‡∏°', '‡∏õ‡∏ß‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢', '‡∏ï‡∏∂‡∏á'],
    '‡πÅ‡∏™‡∏ö': ['‡∏õ‡∏ß‡∏î‡πÅ‡∏™‡∏ö‡∏õ‡∏ß‡∏î‡∏£‡πâ‡∏≠‡∏ô', '‡∏£‡πâ‡∏≠‡∏ô', '‡πÑ‡∏´‡∏°‡πâ', '‡∏£‡∏∞‡∏Ñ‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á', '‡πÅ‡∏™‡∏ö‡πÜ'],
    '‡∏Ñ‡∏±‡∏ô': ['‡∏Ñ‡∏±‡∏ô‡πÜ', '‡∏¢‡∏∏‡∏ö‡∏¢‡∏¥‡∏ö', '‡∏¢‡∏¥‡∏ö‡πÜ', '‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Å‡∏≤', '‡πÄ‡∏Å‡∏≤'],
    '‡∏ï‡∏∏‡πà‡∏°': ['‡πÄ‡∏°‡πá‡∏î', '‡∏ú‡∏∑‡πà‡∏ô', '‡∏™‡∏¥‡∏ß', '‡πÅ‡∏ú‡∏•', '‡∏£‡∏≠‡∏¢‡πÅ‡∏î‡∏á', '‡∏õ‡∏∑‡πâ‡∏ô', '‡∏à‡∏∏‡∏î‡πÅ‡∏î‡∏á'],
    '‡∏õ‡∏≤‡∏Å': ['‡∏£‡∏¥‡∏°‡∏ù‡∏µ‡∏õ‡∏≤‡∏Å', '‡∏°‡∏∏‡∏°‡∏õ‡∏≤‡∏Å', '‡∏£‡∏≠‡∏ö‡∏õ‡∏≤‡∏Å', '‡∏´‡∏ô‡πâ‡∏≤'],
    '‡πÑ‡∏Ç‡πâ': ['‡∏ï‡∏±‡∏ß‡∏£‡πâ‡∏≠‡∏ô', '‡∏£‡∏∏‡∏°‡πÜ', '‡∏Ñ‡∏£‡∏±‡πà‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏Ñ‡∏£‡∏±‡πà‡∏ô‡∏ï‡∏±‡∏ß', '‡∏°‡∏µ‡πÑ‡∏Ç‡πâ', '‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏Ç‡πâ'],
    '‡∏ú‡∏¥‡∏ß': ['‡∏ú‡∏¥‡∏ß‡∏´‡∏ô‡∏±‡∏á', '‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤', '‡∏´‡∏ô‡πâ‡∏≤'],
}

CUSTOM_STOPWORDS = set(thai_stopwords()) | {
    "‡πÄ‡∏õ‡πá‡∏ô", "‡∏°‡∏µ", "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡∏°‡∏≤‡∏Å", "‡πÜ", "‡∏Ñ‡πà‡∏∞", "‡∏Ñ‡∏£‡∏±‡∏ö", 
    "‡∏Ñ‡∏∑‡∏≠", "‡∏ó‡∏µ‡πà", "‡πÅ‡∏•‡∏∞", "‡∏´‡∏£‡∏∑‡∏≠", "‡∏ä‡πà‡∏ß‡∏¢", "‡∏î‡πâ‡∏ß‡∏¢", "‡πÅ‡∏•‡πâ‡∏ß", "‡∏≠‡∏¢‡∏≤‡∏Å", "‡∏ï‡πâ‡∏≠‡∏á",
    "‡∏ô‡∏∞", "‡∏à‡∏∞", "‡πÄ‡∏≠‡∏á", "‡πÑ‡∏î‡πâ", "‡πÑ‡∏õ", "‡∏°‡∏≤", "‡∏≠‡∏¢‡∏π‡πà", "‡πÉ‡∏´‡πâ", "‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì", "‡πÅ‡∏ñ‡∏ß‡πÜ", "‡∏°‡∏±‡∏ô"
}

def expand_synonyms(text):
    text = str(text).lower()
    for main_word, synonyms in SYNONYM_MAP.items():
        for syn in synonyms:
            if syn in text:
                text += f" {main_word}" 
    return text

def thai_tokenizer(text):
    if not isinstance(text, str): return []
    text = expand_synonyms(text) 
    words = word_tokenize(text, engine="newmm", keep_whitespace=False)
    return [w for w in words if w not in CUSTOM_STOPWORDS and len(w) > 1 and not w.isnumeric()]

# ========================================
# üìÇ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Excel/CSV)
# ========================================
print("‚è≥ AI: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
df = None
# ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•
possible_files = ["data.xlsx", "data.csv", "data.xlsx - Sheet1.csv"]

for f in possible_files:
    if os.path.exists(f):
        try:
            if f.endswith('.csv'):
                df = pd.read_csv(f)
            else:
                df = pd.read_excel(f)
            print(f"‚úÖ AI: ‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå {f}")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è AI: ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {f} ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ({e})")

if df is None:
    print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data.xlsx ‡∏´‡∏£‡∏∑‡∏≠ .csv) ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ")
    print("   -> ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå app.py")
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dummy Data ‡∏Å‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏á (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
    # sys.exit() # ‡∏õ‡∏¥‡∏î‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏ó‡∏™ Server
    print("‚ö†Ô∏è ...‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (Dummy) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö...")
    data = {
        '‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ': ['‡∏™‡∏¥‡∏ß‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö', '‡∏ú‡∏∑‡πà‡∏ô‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏û‡πâ'],
        '‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å': ['‡∏ï‡∏∏‡πà‡∏°‡πÅ‡∏î‡∏á ‡πÄ‡∏à‡πá‡∏ö', '‡∏Ñ‡∏±‡∏ô ‡∏ú‡∏∑‡πà‡∏ô‡πÅ‡∏î‡∏á'],
        '‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á': ['‡∏°‡∏µ‡∏´‡∏ô‡∏≠‡∏á', '‡∏ú‡∏¥‡∏ß‡πÅ‡∏´‡πâ‡∏á'],
        '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢': ['‡∏´‡∏ô‡πâ‡∏≤', '‡πÅ‡∏Ç‡∏ô ‡∏Ç‡∏≤'],
        '‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô': ['‡∏•‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î', '‡∏ó‡∏≤‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡πÅ‡∏û‡πâ'],
        '‡∏™‡∏°‡∏∏‡∏ô‡πÑ‡∏û‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á': ['‡∏Ç‡∏°‡∏¥‡πâ‡∏ô‡∏ä‡∏±‡∏ô', '‡∏ß‡πà‡∏≤‡∏ô‡∏´‡∏≤‡∏á‡∏à‡∏£‡∏∞‡πÄ‡∏Ç‡πâ']
    }
    df = pd.DataFrame(data)

# Clean Column Names
df.columns = df.columns.str.strip()

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô
def clean_and_prepare_data(row):
    main = str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å', ''))
    sub = str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á', ''))
    loc = str(row.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢', ''))
    
    # ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ: ‡πÄ‡∏ö‡∏¥‡πâ‡∏•‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    knowledge_text = f"{row['‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ']} {main} {main} {sub} {loc}"
    return knowledge_text

df['knowledge'] = df.apply(lambda x: clean_and_prepare_data(x), axis=1)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏°‡∏≠‡∏á AI
vectorizer = TfidfVectorizer(
    tokenizer=thai_tokenizer,
    ngram_range=(1, 2),
    min_df=1,
    sublinear_tf=True
)

try:
    tfidf_matrix = vectorizer.fit_transform(df['knowledge'])
    print(f"‚úÖ AI: ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô! (‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å {len(df)} ‡πÇ‡∏£‡∏Ñ)")
except Exception as e:
    print(f"‚ùå Error: {e}")
    sys.exit()

# ========================================
# üîå ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: API Endpoint
# ========================================
@app.route('/api/analyze', methods=['POST'])
def analyze():
    # -----------------------------------------------------
    # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á JSON ‡πÅ‡∏•‡∏∞ FormData (‡∏à‡∏≤‡∏Å Node.js)
    # -----------------------------------------------------
    user_input = ""
    
    # 1. ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å FormData (‡∏Å‡∏£‡∏ì‡∏µ Node ‡∏™‡πà‡∏á‡∏°‡∏≤)
    if 'symptoms' in request.form:
        user_input = request.form['symptoms']
    # 2. ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å JSON (‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏ó‡∏™‡∏î‡πâ‡∏ß‡∏¢ Postman)
    elif request.json and 'symptoms' in request.json:
        user_input = request.json['symptoms']
    
    user_input = user_input.strip()
    
    print(f"\nüì© ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: '{user_input}'")
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ô‡∏ö‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ (‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ)
    if 'file' in request.files:
        print(f"üì∏ (‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ô‡∏ö‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢: {request.files['file'].filename}) - ‡πÅ‡∏ï‡πà‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Text ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡πà‡∏≠‡∏ô")

    if not user_input:
        return jsonify({"success": False, "message": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏Å‡∏≤‡∏£"})

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    user_vec = vectorizer.transform([user_input])
    scores = cosine_similarity(user_vec, tfidf_matrix).flatten()
    
    top_indices = scores.argsort()[::-1][:3]
    
    results = []
    found_any = False

    for idx in top_indices:
        score = scores[idx]
        
        # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
        if score > 0.01: 
            found_any = True
            row = df.iloc[idx]
            
            print(f"   üëâ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö: {row['‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ']} (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {score:.4f})")

            warning_msg = ""
            if '‡πÑ‡∏Ç‡πâ' in user_input and '‡πÑ‡∏Ç‡πâ' in str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á', '')):
                warning_msg = "(‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏±‡∏Å‡∏°‡∏µ‡πÑ‡∏Ç‡πâ‡∏£‡πà‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)"

            results.append({
                "disease": str(row['‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ']),
                "confidence": round(score * 100, 2),
                "symptoms": str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å', '')),
                "location": str(row.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢', '')),
                "treatment": str(row.get('‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô', '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå')),
                "warning": warning_msg,
                "herbs": str(row.get('‡∏™‡∏°‡∏∏‡∏ô‡πÑ‡∏û‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á', '-')).split(',')
            })

    if not found_any:
        print("   ‚ùå ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô")
        return jsonify({
            "success": True,
            "found": False,
            "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"
        })

    return jsonify({
        "success": True,
        "found": True,
        "data": results
    })

if __name__ == '__main__':
    print("üöÄ Python Server ‡∏£‡∏±‡∏ô‡∏ó‡∏µ‡πà Port 5001...")
    # üëáüëáüëá ‡πÅ‡∏Å‡πâ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏™‡πà host='0.0.0.0' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏°‡∏î
    app.run(host='0.0.0.0', port=5001, debug=True)
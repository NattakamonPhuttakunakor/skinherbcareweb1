import os
import pandas as pd
import numpy as np
from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# ===============================
# üîê API KEY
# ===============================
API_KEY = os.environ.get("API_KEY") or os.environ.get("PYTHON_API_KEY") or None
if not API_KEY:
    print("‚ö†Ô∏è Warning: API_KEY / PYTHON_API_KEY not set ‚Äî running without API key enforcement")

# ===============================
# üîß Synonym & Tokenizer Config
# ===============================
SYNONYM_MAP = {
    '‡∏õ‡∏ß‡∏î': ['‡πÄ‡∏à‡πá‡∏ö', '‡πÅ‡∏™‡∏ö', '‡∏ö‡∏ß‡∏°', '‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö', '‡∏à‡∏∏‡∏Å‡πÅ‡∏ô‡πà‡∏ô', '‡∏ó‡∏£‡∏°‡∏≤‡∏ô'],
    '‡∏Ñ‡∏±‡∏ô': ['‡∏Ñ‡∏±‡∏ô‡πÜ', '‡∏Ñ‡∏±‡∏ô‡∏°‡∏≤‡∏Å', '‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Å‡∏≤', '‡∏¢‡∏∏‡∏ö‡∏¢‡∏¥‡∏ö'],
    '‡∏ú‡∏∑‡πà‡∏ô': ['‡∏ú‡∏∑‡πà‡∏ô‡πÅ‡∏î‡∏á', '‡∏ú‡∏∑‡πà‡∏ô‡∏Ñ‡∏±‡∏ô', '‡∏ï‡∏∏‡πà‡∏°', '‡∏ï‡∏∏‡πà‡∏°‡πÅ‡∏î‡∏á', '‡∏õ‡∏∑‡πâ‡∏ô', '‡∏•‡∏°‡∏û‡∏¥‡∏©', '‡∏ï‡∏∏‡πà‡∏°‡πÉ‡∏™'],
    '‡πÑ‡∏Ç‡πâ': ['‡∏°‡∏µ‡πÑ‡∏Ç‡πâ', '‡∏ï‡∏±‡∏ß‡∏£‡πâ‡∏≠‡∏ô', '‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏Ç‡πâ', '‡∏£‡∏∏‡∏°‡πÜ'],
    '‡πÅ‡∏Ç‡∏ô': ['‡∏ï‡πâ‡∏ô‡πÅ‡∏Ç‡∏ô', '‡∏õ‡∏•‡∏≤‡∏¢‡πÅ‡∏Ç‡∏ô', '‡∏Ç‡πâ‡∏≠‡∏®‡∏≠‡∏Å', '‡∏°‡∏∑‡∏≠'],
    '‡∏Ç‡∏≤': ['‡∏ï‡πâ‡∏ô‡∏Ç‡∏≤', '‡∏ô‡πà‡∏≠‡∏á', '‡πÄ‡∏ó‡πâ‡∏≤', '‡πÄ‡∏Ç‡πà‡∏≤'],
    '‡∏°‡∏≤‡∏Å': ['‡∏°‡∏≤‡∏Å‡πÜ', '‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡πÄ‡∏¢‡∏≠‡∏∞', '‡∏´‡∏ô‡∏±‡∏Å', '‡πÑ‡∏°‡πà‡πÑ‡∏´‡∏ß'],
}

CUSTOM_STOPWORDS = {
    "‡πÄ‡∏õ‡πá‡∏ô", "‡∏°‡∏µ", "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£", "‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡∏°‡∏≤‡∏Å", "‡πÜ", "‡∏Ñ‡πà‡∏∞", "‡∏Ñ‡∏£‡∏±‡∏ö",
    "‡∏Ñ‡∏∑‡∏≠", "‡∏ó‡∏µ‡πà", "‡πÅ‡∏•‡∏∞", "‡∏´‡∏£‡∏∑‡∏≠", "‡∏ä‡πà‡∏ß‡∏¢", "‡∏î‡πâ‡∏ß‡∏¢", "‡πÅ‡∏•‡πâ‡∏ß", "‡∏≠‡∏¢‡∏≤‡∏Å", "‡∏ï‡πâ‡∏≠‡∏á",
    "‡∏ô‡∏∞", "‡∏à‡∏∞", "‡πÄ‡∏≠‡∏á", "‡πÑ‡∏î‡πâ", "‡πÑ‡∏õ", "‡∏°‡∏≤", "‡∏≠‡∏¢‡∏π‡πà", "‡πÉ‡∏´‡πâ", "‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì", "‡πÅ‡∏ñ‡∏ß‡πÜ"
}

def expand_synonyms(text):
    """‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå (Synonym Expansion)"""
    text = str(text).lower()
    for main_word, synonyms in SYNONYM_MAP.items():
        for syn in synonyms:
            if syn in text:
                text += f" {main_word}"
    return text

def thai_tokenizer(text):
    """Tokenize Thai text"""
    if not isinstance(text, str):
        return []
    text = expand_synonyms(text)
    try:
        from pythainlp.tokenize import word_tokenize
        words = word_tokenize(text, engine="newmm", keep_whitespace=False)
    except:
        words = text.split()
    return [w for w in words if w not in CUSTOM_STOPWORDS and len(w) > 1 and not w.isnumeric()]

# ===============================
# üìÇ Load & Prepare Data
# ===============================
df = None
try:
    for filename in ["data.xlsx", "data.csv", "dataset.xlsx", "data2.xlsx", "herbs_all1.csv"]:
        if os.path.exists(filename):
            try:
                if filename.endswith(".xlsx"):
                    df = pd.read_excel(filename)
                else:
                    df = pd.read_csv(filename)
                print(f"‚úÖ Loaded: {filename}")
                break
            except Exception as inner_e:
                print(f"‚ö†Ô∏è Failed to parse {filename}: {inner_e}")
                continue
except Exception as e:
    print(f"‚ö†Ô∏è Load file error: {e}")

if df is None:
    print("‚ö†Ô∏è Using Dummy Data")
    df = pd.DataFrame({
        "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ": ["‡∏™‡∏¥‡∏ß‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö", "‡∏ú‡∏∑‡πà‡∏ô‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏û‡πâ", "‡∏•‡∏°‡∏û‡∏¥‡∏©"],
        "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å": ["‡∏ï‡∏∏‡πà‡∏°‡πÅ‡∏î‡∏á ‡πÄ‡∏à‡πá‡∏ö ‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏±‡∏ô", "‡∏Ñ‡∏±‡∏ô ‡∏ú‡∏∑‡πà‡∏ô‡πÅ‡∏î‡∏á", "‡∏ï‡∏±‡∏ß‡πÅ‡∏î‡∏á ‡∏Ñ‡∏±‡∏ô‡∏°‡∏≤‡∏Å"],
        "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á": ["‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ú‡∏¥‡∏ß‡∏£‡∏∞‡∏Ñ‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á", "‡∏õ‡∏∑‡πâ‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà"],
        "‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô": ["‡∏•‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î", "‡∏ó‡∏≤‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡πÅ‡∏û‡πâ", "‡∏õ‡∏£‡∏∞‡∏Ñ‡∏ö‡πÄ‡∏¢‡πá‡∏ô"]
    })

df.columns = df.columns.str.strip()

def clean_and_prepare_data(row):
    """Clean and prepare knowledge text for AI"""
    main = str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å', ''))
    sub = str(row.get('‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á', '') or '')
    loc = str(row.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢', '') or '')
    treatment = str(row.get('‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô', '') or '')
    
    if '‡πÑ‡∏Ç‡πâ' in treatment and '‡πÑ‡∏Ç‡πâ' not in sub:
        sub += " ‡∏°‡∏µ‡πÑ‡∏Ç‡πâ"
    
    knowledge_text = f"{row['‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ']} {main} {main} {sub} {loc} {loc}"
    return knowledge_text

df['knowledge'] = df.apply(clean_and_prepare_data, axis=1)

# ===============================
# üìÇ Load Data (‡∏°‡∏µ Dummy ‡∏Å‡∏±‡∏ô‡∏û‡∏±‡∏á)
# ===============================
df = None
try:
    # Try multiple file names (order matters ‚Äî most specific first)
    for f in ["data.xlsx", "data.csv", "dataset.xlsx", "data2.xlsx", "herbs_all1.csv"]:
        if os.path.exists(f):
            try:
                if f.endswith(".xlsx"):
                    df = pd.read_excel(f)
                else:
                    df = pd.read_csv(f)
                print("‚úÖ Loaded:", f)
                break
            except Exception as inner_e:
                print(f"‚ö†Ô∏è Failed to parse {f}:", inner_e)
                continue
except Exception as e:
    print("‚ö†Ô∏è Load file error:", e)

if df is None:
    print("‚ö†Ô∏è Using Dummy Data")
    df = pd.DataFrame({
        "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ": ["‡∏™‡∏¥‡∏ß‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö", "‡∏ú‡∏∑‡πà‡∏ô‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏û‡πâ"],
        "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å": ["‡∏ï‡∏∏‡πà‡∏°‡πÅ‡∏î‡∏á ‡πÄ‡∏à‡πá‡∏ö ‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏±‡∏ô", "‡∏Ñ‡∏±‡∏ô ‡∏ú‡∏∑‡πà‡∏ô‡πÅ‡∏î‡∏á"],
        "‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô": ["‡∏•‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î", "‡∏ó‡∏≤‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡πÅ‡∏û‡πâ"]
    })

# ===============================
# ü§ñ AI (TF-IDF with improved tokenizer)
# ===============================
vectorizer = None
tfidf_matrix = None

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity

    print("üß† Training AI model...")
    vectorizer = TfidfVectorizer(
        tokenizer=thai_tokenizer,
        ngram_range=(1, 2),
        min_df=1,
        sublinear_tf=True
    )
    tfidf_matrix = vectorizer.fit_transform(df['knowledge'])
    print(f"‚úÖ AI Ready ({len(df)} diseases)")
except Exception as e:
    print(f"‚ö†Ô∏è AI init error: {e}")
    vectorizer = None
    tfidf_matrix = None

# ===============================
# üè• Health Check
# ===============================
@app.route("/", methods=["GET"])
def health():
    return jsonify({
        "success": True,
        "message": "Python AI Service Running",
        "ai_ready": vectorizer is not None,
        "data_loaded": df is not None,
        "api_key_configured": bool(API_KEY)
    })

@app.route("/status", methods=["GET"])
def status():
    # More detailed health info for orchestrators
    return jsonify({
        "success": True,
        "ai_ready": vectorizer is not None,
        "data_loaded": df is not None,
        "api_key_configured": bool(API_KEY)
    })

# ===============================
# üîÆ Predict
# ===============================
@app.route("/predict", methods=["POST"])
def predict():
    # üîê check key
    print('üßæ Incoming headers:', dict(request.headers))
    client_key = request.headers.get("x-api-key")
    # If API_KEY is configured, enforce exact match. If not configured, allow but log.
    if API_KEY:
        if not client_key:
            return jsonify({"success": False, "message": "API Key not found"}), 401
        if client_key != API_KEY:
            return jsonify({"success": False, "message": "API Key mismatch"}), 401
    else:
        print("‚ö†Ô∏è API key not configured on server ‚Äî skipping enforcement")

    data = request.get_json(silent=True)
    if not data or "symptoms" not in data:
        return jsonify({
            "success": False,
            "message": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏Å‡∏≤‡∏£"
        }), 400

    symptoms = data["symptoms"].strip()
    if symptoms == "":
        return jsonify({
            "success": False,
            "message": "‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤"
        }), 400

    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    if vectorizer and tfidf_matrix is not None:
        try:
            vec = vectorizer.transform([symptoms])
            scores = cosine_similarity(vec, tfidf_matrix).flatten()
            top_indices = scores.argsort()[::-1][:3]
            
            results = []
            for idx in top_indices:
                score = scores[idx]
                if score > 0.1:  # Confidence threshold 10%
                    row = df.iloc[idx]
                    results.append({
                        "disease": row["‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ"],
                        "confidence": round(float(score) * 100, 2),
                        "main_symptoms": row.get("‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å", ""),
                        "secondary_symptoms": row.get("‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á", ""),
                        "recommendation": row.get("‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏ï‡πâ‡∏ô", "")
                    })
            
            if results:
                best = results[0]
                return jsonify({
                    "success": True,
                    "prediction": best["disease"],
                    "confidence": best["confidence"],
                    "recommendation": best["recommendation"],
                    "data": results,
                    "found": True
                })
            else:
                return jsonify({
                    "success": False,
                    "found": False,
                    "prediction": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
                    "confidence": 0,
                    "recommendation": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
                })
        except Exception as e:
            print(f"‚ùå Predict error: {e}")
            return jsonify({
                "success": False,
                "message": f"Error: {str(e)}"
            }), 500

    return jsonify({
        "success": False,
        "found": False,
        "prediction": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô",
        "confidence": 0,
        "recommendation": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
    })

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5001))
    app.run(host="0.0.0.0", port=port)
